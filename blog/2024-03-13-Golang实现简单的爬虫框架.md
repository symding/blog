---
title: 使用Golang实现简单的爬虫框架
tags: [Golang,爬虫]
---

> 相比scrapy能实现更低的资源占用，可以在一些低性能服务器上部署爬虫负载。
<!--truncate-->
## 架构
需要一个基础的结构体 `Spider` 来管理整个爬虫的运行周期，该结构体含有一下成员:
* `RequestQueue`: 请求队列
* `ResponseQueue`: 响应队列
* `Client`: HTTP客户端
同时提供一个构造函数 `NewSpider`

```Go title="spider.go"
package gospider

func NewSpider() Spider {
    return Spider{
        RequestQueue :  make(chan *http.Request,2)
        ResponseQueue:  make(chan *http.Response)
        Client:         &http.Client{
                            Timeout:   time.Second * 30}
                        }
}

type Spider struct {
    RequestQueue chan *http.Request
    ResponseQueue chan *http.Response
    Client *http.Client
}
```
### 队列控制
队列管理需要实现两个函数: **添加请求**以及**获得响应**
```Go title="spider.go"
func (s *Spider) AddRequest(r Request) {
    s.RequestQueue <- r
}

func (s *Spider) GetResponse() (Response, error) {
	resp, ok := <-s.ResponseQueue
	if ok {
		return resp, nil
	}
	return Response{}, fmt.Errorf("Response queue closed.\n")
}
```
### 消费
`Run` 函数获取 `RequestQueue` 队列中的任务并生成请求，HTTP客户端消费此请求后将获得的响应放入`ResponseQueue`.
``` Go title="spider.go"
func (s *Spider) Run() {
    defer close(s.ResponseQueue)
    for {
        request,ok := <- s.RequestQueue
        if !ok {
            break
        }
        response,err := s.Client.Do(request)
        s.ResponseQueue <- response
    }
}
```
### Demo 
```go title="demo.go"
package main
func main() {
    spider := gospider.NewSpider()
    go spider.Run()
    go func () {
        for {
            // ******
            // 此处构建http请求
            spider.AddRequest(request)
        }
    }
    for {
        response,ok := <- spider.ResponseQueue
        if !ok {
            break
        }
        // 此处解析响应并获得数据
    }
}
```
